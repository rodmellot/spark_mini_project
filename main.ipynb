{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rodmellot/spark_mini_project/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BLABLABLA"
      ],
      "metadata": {
        "id": "Lru6lTKX4aQn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import yaml\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "zt92IhK55QMA"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Collection"
      ],
      "metadata": {
        "id": "evIFEPBf4iuY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YWyyfEc9rasZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12bcdafd-9752-477a-de30-e5c108a1fe68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Fetching Configuration ---\n",
            "Configuration loaded successfully.\n",
            "\n",
            "--- Downloading Datasets ---\n",
            "Downloading: Prix2022_part1.csv...\n",
            "Saved to ./data/Prix2022_part1.csv\n",
            "Downloading: Prix2022_part2.csv...\n",
            "Saved to ./data/Prix2022_part2.csv\n",
            "Downloading: Prix2023.csv...\n",
            "Saved to ./data/Prix2023.csv\n",
            "Downloading: Prix2024.csv...\n",
            "Saved to ./data/Prix2024.csv\n",
            "Downloading: Stations2024.csv...\n",
            "Saved to ./data/Stations2024.csv\n",
            "Downloading: Services2024.csv...\n",
            "Saved to ./data/Services2024.csv\n",
            "\n",
            "Data collection complete. Files ready for Spark processing.\n"
          ]
        }
      ],
      "source": [
        "# As mentioned, i created a config.yaml stocked on the github page.\n",
        "#The link by (raw) url allows us to work easily on colab and do not have to clone the repo.\n",
        "YAML_URL = \"https://raw.githubusercontent.com/rodmellot/spark_mini_project/refs/heads/main/config.yaml\"\n",
        "\n",
        "# Download the YAML file to the local Colab environment and load config globally\n",
        "print(\"--- Fetching Configuration ---\")\n",
        "response = requests.get(YAML_URL)\n",
        "config = yaml.safe_load(response.content)\n",
        "print(\"Configuration loaded successfully.\\n\")\n",
        "\n",
        "def setup_project_data(data_dir, base_url, files_to_download):\n",
        "    os.makedirs(data_dir, exist_ok=True)\n",
        "    print(\"--- Downloading Datasets ---\")\n",
        "    for file_name in files_to_download:\n",
        "        file_url = f\"{base_url}/{file_name}\"\n",
        "        target_path = os.path.join(data_dir, file_name)\n",
        "\n",
        "        print(f\"Downloading: {file_name}...\")\n",
        "        file_response = requests.get(file_url)\n",
        "\n",
        "        with open(target_path, 'wb') as f:\n",
        "            f.write(file_response.content)\n",
        "        print(f\"Saved to {target_path}\")\n",
        "\n",
        "    print(\"\\nData collection complete. Files ready for Spark processing.\")\n",
        "\n",
        "#Initialization in our case using the globally loaded config\n",
        "data_dir = config.get('data_directory', './data')\n",
        "base_url = config.get('base_url', 'https://raw.githubusercontent.com/rvm-courses/GasPrices/main')\n",
        "files_to_download = [\n",
        "        \"Prix2022_part1.csv\",\n",
        "        \"Prix2022_part2.csv\", # 2022 is in two parts\n",
        "        \"Prix2023.csv\",\n",
        "        \"Prix2024.csv\",\n",
        "        \"Stations2024.csv\",\n",
        "        \"Services2024.csv\"\n",
        "    ]\n",
        "\n",
        "# Do the actual collection\n",
        "setup_project_data(data_dir, base_url, files_to_download)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialization Spark Session"
      ],
      "metadata": {
        "id": "Gka0IESj707v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import input_file_name, lit\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"FuelPriceAnalysis\") \\\n",
        "    .config(\"spark.sql.session.timeZone\", \"UTC\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "gQXZG-Yh76oE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation – step 1"
      ],
      "metadata": {
        "id": "iVQ2bGrC41eY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining the Schema\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "*Column Name,Type,Description*\n",
        "\n",
        "id_station,String,Unique identifier for the station\n",
        "\n",
        "code_postal,String,Postal code (kept as string to preserve leading zeros)\n",
        "\n",
        "date,Timestamp,Date and time of the price update\n",
        "\n",
        "valeur,Double,\"The price of the fuel (e.g., 1.859)\"\n",
        "\n",
        "nom_carburant,String,\"Type of fuel (Gazole, E10, etc.)\""
      ],
      "metadata": {
        "id": "WuLI57vj86ZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading price data with a wildcard to capture all years\n",
        "prices_df = spark.read.format(\"csv\") \\\n",
        "    .option(\"header\", \"true\") \\\n",
        "    .option(\"sep\", \";\") \\\n",
        "    .load(\"./data/Prix202*.csv\") \\\n",
        "    .withColumn(\"source_file\", input_file_name())\n",
        "\n",
        "# Loading reference data\n",
        "stations_df = spark.read.option(\"header\", \"true\").option(\"sep\", \";\").csv(\"./data/Stations2024.csv\")\n",
        "services_df = spark.read.option(\"header\", \"true\").option(\"sep\", \";\").csv(\"./data/Services2024.csv\")"
      ],
      "metadata": {
        "id": "TIjMyInl6MKq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "# 1. Configuration\n",
        "# Base URL for the raw files\n",
        "base_url = \"https://raw.githubusercontent.com/rvm-courses/GasPrices/master\"\n",
        "output_folder = \"./data\"\n",
        "filenames = [\n",
        "    \"Prix2022S1.csv.gz\",\n",
        "    \"Prix2022S2.csv.gz\",\n",
        "    \"Prix2023.csv.gz\",\n",
        "    \"Prix2024.csv.gz\",\n",
        "    \"Stations2024.csv.gz\",\n",
        "    \"Services2024.csv.gz\"\n",
        "]\n",
        "\n",
        "# 2. Create the directory if it doesn't exist\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# 3. Download the files\n",
        "print(f\"--- Starting Download into {output_folder} ---\")\n",
        "\n",
        "for filename in filenames:\n",
        "    # Construct the full URL and local path\n",
        "    url = f\"{base_url}/{filename}\"\n",
        "    output_path = os.path.join(output_folder, filename)\n",
        "\n",
        "    print(f\"Downloading {filename}...\")\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, stream=True)\n",
        "\n",
        "        # Check if the request was successful (Status Code 200)\n",
        "        if response.status_code == 200:\n",
        "            with open(output_path, 'wb') as f:\n",
        "                for chunk in response.iter_content(chunk_size=8192):\n",
        "                    f.write(chunk)\n",
        "            print(f\" -> Success! Saved to: {output_path}\")\n",
        "\n",
        "            # Optional: Verify it's not an HTML error page by checking size\n",
        "            file_size = os.path.getsize(output_path)\n",
        "            if file_size < 1000:\n",
        "                print(\"    [Warning] File is very small. Check if it contains an error message.\")\n",
        "\n",
        "        else:\n",
        "            print(f\" -> Failed. Status Code: {response.status_code} (URL: {url})\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" -> Error occurred: {e}\")\n",
        "\n",
        "print(\"\\nAll downloads finished.\")"
      ],
      "metadata": {
        "id": "1H9drqENkFRu",
        "outputId": "6a3d8173-4ede-4e74-99b3-211a8b7c54c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Download into ./data ---\n",
            "Downloading Prix2022S1.csv.gz...\n",
            " -> Success! Saved to: ./data/Prix2022S1.csv.gz\n",
            "Downloading Prix2022S2.csv.gz...\n",
            " -> Success! Saved to: ./data/Prix2022S2.csv.gz\n",
            "Downloading Prix2023.csv.gz...\n",
            " -> Success! Saved to: ./data/Prix2023.csv.gz\n",
            "Downloading Prix2024.csv.gz...\n",
            " -> Success! Saved to: ./data/Prix2024.csv.gz\n",
            "Downloading Stations2024.csv.gz...\n",
            " -> Success! Saved to: ./data/Stations2024.csv.gz\n",
            "Downloading Services2024.csv.gz...\n",
            " -> Success! Saved to: ./data/Services2024.csv.gz\n",
            "\n",
            "All downloads finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, LongType\n",
        "from pyspark.sql.functions import col, to_timestamp, year, month, weekofyear, desc, regexp_replace\n",
        "\n",
        "# Initialize Spark\n",
        "spark = SparkSession.builder.appName(\"GasPriceProject\").getOrCreate()\n",
        "\n",
        "# 1. Define Schemas\n",
        "price_schema = StructType([\n",
        "    StructField(\"id_station\", StringType(), True),\n",
        "    StructField(\"code_postal\", StringType(), True),\n",
        "    StructField(\"pop\", StringType(), True),\n",
        "    StructField(\"latitude\", LongType(), True),\n",
        "    StructField(\"longitude\", LongType(), True),\n",
        "    StructField(\"date\", StringType(), True),\n",
        "    StructField(\"id_carburant\", StringType(), True),\n",
        "    StructField(\"nom_carburant\", StringType(), True),\n",
        "    StructField(\"valeur\", DoubleType(), True)\n",
        "])\n",
        "\n",
        "station_schema = StructType([\n",
        "    StructField(\"id_station\", StringType(), True),\n",
        "    StructField(\"code_postal\", StringType(), True),\n",
        "    StructField(\"type\", StringType(), True),\n",
        "    StructField(\"latitude\", LongType(), True),\n",
        "    StructField(\"longitude\", LongType(), True),\n",
        "    StructField(\"address\", StringType(), True),\n",
        "    StructField(\"ville\", StringType(), True)\n",
        "])\n",
        "\n",
        "# 2. Read Data\n",
        "print(\"--- Reading Data ---\")\n",
        "raw_prices_df = spark.read \\\n",
        "    .option(\"header\", \"false\") \\\n",
        "    .option(\"sep\", \";\") \\\n",
        "    .schema(price_schema) \\\n",
        "    .csv(\"./data/Prix*.csv.gz\")\n",
        "\n",
        "stations_df = spark.read \\\n",
        "    .option(\"header\", \"false\") \\\n",
        "    .option(\"sep\", \"|\") \\\n",
        "    .schema(station_schema) \\\n",
        "    .csv(\"./data/Stations*.csv*\")\n",
        "\n",
        "# 3. Process Data\n",
        "print(\"--- Processing Dates & Locations ---\")\n",
        "\n",
        "# 'T' in place of ' ' so all dates match \"yyyy-MM-dd HH:mm:ss\"\n",
        "# This prevents the ANSI strict mode crash.\n",
        "prices_processed_df = raw_prices_df \\\n",
        "    .withColumn(\"date_clean\", regexp_replace(col(\"date\"), \"T\", \" \")) \\\n",
        "    .withColumn(\"date_ts\", to_timestamp(col(\"date_clean\"), \"yyyy-MM-dd HH:mm:ss\")) \\\n",
        "    .withColumn(\"year\", year(\"date_ts\")) \\\n",
        "    .withColumn(\"month\", month(\"date_ts\")) \\\n",
        "    .withColumn(\"week_of_year\", weekofyear(\"date_ts\")) \\\n",
        "    .drop(\"date_clean\") # Clean up temporary column\n",
        "\n",
        "# Process Lat/Long\n",
        "stations_processed_df = stations_df \\\n",
        "    .withColumn(\"latitude_clean\", col(\"latitude\") / 100000) \\\n",
        "    .withColumn(\"longitude_clean\", col(\"longitude\") / 100000)\n",
        "\n",
        "# 4. Filter & Create Tables\n",
        "\n",
        "prices_processed_df.createOrReplaceTempView(\"gas_prices_raw\")\n",
        "stations_processed_df.createOrReplaceTempView(\"stations_clean\")\n",
        "\n",
        "print(\"--- Gas Type Distribution ---\")\n",
        "gas_stats = prices_processed_df.groupBy(\"nom_carburant\").count().orderBy(desc(\"count\"))\n",
        "gas_stats.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Take the top 4 found in the data.\n",
        "all_fuels = [row['nom_carburant'] for row in gas_stats.collect() if row['nom_carburant'] is not None]\n",
        "selected_fuels = all_fuels[:4]\n",
        "\n",
        "print(f\"Keeping Top 4 Fuels: {selected_fuels}\")\n",
        "\n",
        "final_prices_df = prices_processed_df.filter(col(\"nom_carburant\").isin(selected_fuels))\n",
        "final_prices_df.createOrReplaceTempView(\"gas_prices\")\n",
        "\n",
        "print(\"Data Preparation Step 1 Complete.\")\n",
        "final_prices_df.show(5)\n",
        "stations_processed_df.show(5)"
      ],
      "metadata": {
        "id": "EE_8oEF7mLeu",
        "outputId": "638badde-6ec4-4712-952d-c50dd8af53e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Reading Data ---\n",
            "--- Processing Dates & Locations ---\n",
            "--- Gas Type Distribution ---\n",
            "+-------------+-------+\n",
            "|nom_carburant|  count|\n",
            "+-------------+-------+\n",
            "|       Gazole|4245380|\n",
            "|          E10|3559498|\n",
            "|         SP98|3425844|\n",
            "|          E85|1390580|\n",
            "|         SP95| 961020|\n",
            "|         GPLc| 619759|\n",
            "|         NULL|  12756|\n",
            "+-------------+-------+\n",
            "\n",
            "Keeping Top 4 Fuels: ['Gazole', 'E10', 'SP98', 'E85']\n",
            "Data Preparation Step 1 Complete.\n",
            "+----------+-----------+---+--------+---------+-------------------+------------+-------------+------+-------------------+----+-----+------------+\n",
            "|id_station|code_postal|pop|latitude|longitude|               date|id_carburant|nom_carburant|valeur|            date_ts|year|month|week_of_year|\n",
            "+----------+-----------+---+--------+---------+-------------------+------------+-------------+------+-------------------+----+-----+------------+\n",
            "|   1000001|      01000|  R| 4620100|   519800|2023-01-02T07:53:26|           1|       Gazole| 1.867|2023-01-02 07:53:26|2023|    1|           1|\n",
            "|   1000001|      01000|  R| 4620100|   519800|2023-01-05T09:33:37|           1|       Gazole| 1.877|2023-01-05 09:33:37|2023|    1|           1|\n",
            "|   1000001|      01000|  R| 4620100|   519800|2023-01-09T14:51:49|           1|       Gazole| 1.875|2023-01-09 14:51:49|2023|    1|           2|\n",
            "|   1000001|      01000|  R| 4620100|   519800|2023-01-11T09:23:54|           1|       Gazole| 1.859|2023-01-11 09:23:54|2023|    1|           2|\n",
            "|   1000001|      01000|  R| 4620100|   519800|2023-01-13T09:07:40|           1|       Gazole| 1.862|2023-01-13 09:07:40|2023|    1|           2|\n",
            "+----------+-----------+---+--------+---------+-------------------+------------+-------------+------+-------------------+----+-----+------------+\n",
            "only showing top 5 rows\n",
            "+----------+-----------+----+--------+---------+--------------------+--------------------+--------------+---------------+\n",
            "|id_station|code_postal|type|latitude|longitude|             address|               ville|latitude_clean|longitude_clean|\n",
            "+----------+-----------+----+--------+---------+--------------------+--------------------+--------------+---------------+\n",
            "|   1000001|      01000|   R| 4620100|   519800|596 AVENUE DE TRE...|SAINT-DENIS-LèS-B...|        46.201|          5.198|\n",
            "|   1000002|      01000|   R| 4621842|   522767| 16 Avenue de Marboz|     BOURG-EN-BRESSE|      46.21842|        5.22767|\n",
            "|   1000004|      01000|   R| 4618800|   524500|20 Avenue du Maré...|     Bourg-en-Bresse|        46.188|          5.245|\n",
            "|   1000005|      01000|   R|    NULL|     NULL|642 Avenue de Tré...|SAINT-DENIS-LèS-B...|          NULL|           NULL|\n",
            "|   1000006|      01000|   R| 4620754|   523758|1 Boulevard John ...|     BOURG-EN-BRESSE|      46.20754|        5.23758|\n",
            "+----------+-----------+----+--------+---------+--------------------+--------------------+--------------+---------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import avg, col, min as min_, lit, round\n",
        "\n",
        "\n",
        "# 1. Compute Week Index\n",
        "\n",
        "\n",
        "#(Year - StartYear) * 52 + WeekOfYear\n",
        "\n",
        "#get the first year in the dataset\n",
        "min_year = final_prices_df.select(min_(\"year\")).first()[0]\n",
        "print(f\"Starting Year for Indexing: {min_year}\")\n",
        "\n",
        "#calculate week index\n",
        "df_with_weeks = final_prices_df.withColumn(\n",
        "    \"week_index\",\n",
        "    (col(\"year\") - min_year) * 52 + col(\"week_of_year\")\n",
        ")\n",
        "\n",
        "\n",
        "# 2. National Daily Average\n",
        "\n",
        "# average price per gas type, per day, across all of France\n",
        "\n",
        "daily_avg_df = df_with_weeks.groupBy(\"date_ts\", \"nom_carburant\") \\\n",
        "    .agg(avg(\"valeur\").alias(\"avg_day_price\"))\n",
        "\n",
        "# 3. Compute Price Index\n",
        "#join the averages back to the main data\n",
        "\n",
        "#join on Date and Gas Type\n",
        "df_indexed = df_with_weeks.join(\n",
        "    daily_avg_df,\n",
        "    on=[\"date_ts\", \"nom_carburant\"],\n",
        "    how=\"inner\"\n",
        ")\n",
        "\n",
        "#Apply Formula: 100 * ((Price - Avg) / Avg + 1)\n",
        "final_df = df_indexed.withColumn(\n",
        "    \"price_index\",\n",
        "    round(100 * ((col(\"valeur\") - col(\"avg_day_price\")) / col(\"avg_day_price\") + 1), 2)\n",
        ")\n",
        "# 4. Final Review\n",
        "# Make this final rich dataset available for SQL\n",
        "final_df.createOrReplaceTempView(\"gas_prices_enhanced\")\n",
        "\n",
        "print(\"Data Preparation Step 2 Complete.\")\n",
        "final_df.select(\"date_ts\", \"nom_carburant\", \"valeur\", \"avg_day_price\", \"price_index\", \"week_index\").show(10)"
      ],
      "metadata": {
        "id": "4fcAtztWnEch",
        "outputId": "a024aada-b4bb-428b-d21d-05b741da75b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Year for Indexing: 2022\n",
            "Data Preparation Step 2 Complete.\n",
            "+-------------------+-------------+------+------------------+-----------+----------+\n",
            "|            date_ts|nom_carburant|valeur|     avg_day_price|price_index|week_index|\n",
            "+-------------------+-------------+------+------------------+-----------+----------+\n",
            "|2022-01-01 00:01:00|       Gazole| 1.662|1.5978782122905013|     104.01|        52|\n",
            "|2022-01-01 00:01:00|       Gazole| 1.554|1.5978782122905013|      97.25|        52|\n",
            "|2022-01-01 00:01:00|       Gazole| 1.577|1.5978782122905013|      98.69|        52|\n",
            "|2022-01-01 00:01:00|       Gazole| 1.566|1.5978782122905013|       98.0|        52|\n",
            "|2022-01-01 00:01:00|       Gazole| 1.535|1.5978782122905013|      96.06|        52|\n",
            "|2022-01-01 00:01:00|       Gazole| 1.535|1.5978782122905013|      96.06|        52|\n",
            "|2022-01-01 00:01:00|       Gazole| 1.637|1.5978782122905013|     102.45|        52|\n",
            "|2022-01-01 00:01:00|       Gazole| 1.647|1.5978782122905013|     103.07|        52|\n",
            "|2022-01-01 00:01:00|       Gazole| 1.539|1.5978782122905013|      96.32|        52|\n",
            "|2022-01-01 00:01:00|       Gazole| 1.537|1.5978782122905013|      96.19|        52|\n",
            "+-------------------+-------------+------+------------------+-----------+----------+\n",
            "only showing top 10 rows\n"
          ]
        }
      ]
    }
  ]
}